{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (do_lda.py, line 107)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Anacond\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2910\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-83242ad59845>\"\u001b[1;36m, line \u001b[1;32m6\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from run.fonctions_outils.do_lda import main as do_lda\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\fatsall\\Documents\\Stage\\EDF\\run\\fonctions_outils\\do_lda.py\"\u001b[1;36m, line \u001b[1;32m107\u001b[0m\n\u001b[1;33m    frequence = pd.DataFrame(lda.components_)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "# Importer les packages et modules utiles\n",
    "#------------------------------------------------------------------------------\n",
    "from __future__ import division\n",
    "import os\n",
    "import pandas as pd\n",
    "from run.fonctions_outils.do_lda import main as do_lda\n",
    "from run.fonctions_outils.stats_descs import stats_descs\n",
    "from run.fonctions_outils.stats_descs import stats_tags\n",
    "from run.fonctions_outils.kw_tag import main as kw_tag\n",
    "from run.fonctions_outils.emoji_tag import main as emoji_tag\n",
    "import nltk as nltk\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Paramètre à configurer & Connexion\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "#TODO : Faire un fichier avec les infos de paramétrage de la requête + copie de paramétrage dans fichier de sortie\n",
    "\n",
    "#Paramètre de personnalisation des sorties\n",
    "enterprise_name='EDF'\n",
    "\n",
    "#TODO : construire root dir de manière standard :\n",
    "##TODO :  root_dir  = \"C:/Users/Rapabitb/Documents/PythonScripts/\"\n",
    "##TODO :  client_data_dir= [root_dir  ,enterprise_name,\"/BW data/\"]\n",
    "##TODO :  comme ça on a tous une manière standard d'enregistrer nos données, il suffit de renseigner le nom du client\n",
    "\n",
    "#Répertoire des datas\n",
    "\n",
    "#root_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) + \"/PernodRicard - DataIndia (en)/\"\n",
    "root_dir = \"C:/Users/fatsall/Documents/Stage/EDF/data (FR)\"\n",
    "\n",
    "\n",
    "data_dir = [x[0] for x in os.walk(root_dir)]\n",
    "\n",
    "#Paramètre du LDA\n",
    "n_features=1000\n",
    "n_topics=30\n",
    "n_top_words=50\n",
    "\n",
    "#Si on veut tagger les posts\n",
    "is_tag=0\n",
    "\n",
    "#Répertoire courant print(os.getcwd())\n",
    "\n",
    "title = data_dir[1].split(\" - \", 1)[1]\n",
    "print(title)\n",
    "\n",
    "writer = pd.ExcelWriter(os.getcwd()+'/Resultats/' + enterprise_name + '_result_' + title + '.xlsx',\n",
    "                             engine='xlsxwriter',\n",
    "                             options={'strings_to_urls': False})\n",
    "\n",
    "def retraitement(doc):\n",
    "    doc = ' '.join(word for word in str(doc).split(' ') if not '.' in word and not '/' in word) # strip urls\n",
    "    doc = ' '.join(word for word in str(doc).split(' ') if not word.startswith('#'))  # strip hashtags\n",
    "    doc = ' '.join(word for word in str(doc).split(' ') if not word.startswith('@'))  # strip mentions\n",
    "    doc = np.unicode(doc).lower().replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\t\", '').replace(\"\\\"\", \" \").replace(\n",
    "        \"'\", ' ').replace(\"-\", \" \")\n",
    "    doc = doc.translate({ord(x): None for x in string.punctuation})  # strip punctuations\n",
    "    doc = doc.translate({ord(x): None for x in '0123456789'})  # strip numbers\n",
    "    doc = re.sub(' +', ' ', doc)  # strip double spaces\n",
    "    #strip accents\n",
    "    #doc = doc.translate(str.maketrans(\"āãàäâéèêëïîöôüûùÑŃńǸǹŇň\", \"aaaaaeeeeiioouuunnnnnnn\"))\n",
    "\n",
    "    return doc\n",
    "\n",
    "df = pd.read_excel(\"C:/Users/fatsall/Documents/Stage/EDF/data (FR)/EDF - FR/corpus_faq_EDF_Entreprises.xlsx\")\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "df['nb_word'] = df['fulltext'].apply(lambda x: str(x).count(\" \"))\n",
    "df[\"fulltext_original\"] = df[\"fulltext\"]\n",
    "df.head()\n",
    "\n",
    "df[\"fulltext\"]= df[\"fulltext\"].apply(lambda x: retraitement(x))\n",
    "#suppression des rt\n",
    "df = df[~df.fulltext.str.startswith('rt ')]\n",
    "# Suppression des posts sans texte\n",
    "\n",
    "df=df[(df[\"fulltext\"].notnull())|(df[\"fulltext\"].str!='nan')]\n",
    "\n",
    "df['longueur']=df['fulltext'].apply(lambda x:len(str(x)))\n",
    "df=df[df['longueur']>6]\n",
    "df= df.reset_index()\n",
    "len(df.index)\n",
    "\n",
    "\n",
    "print(\"End Cleaning file : \"+str(len(df.index)))\n",
    "\n",
    "data_samples = df['fulltext'].tolist()\n",
    "lang='french'\n",
    "#data_samples = df['fulltext'].str.encode('utf8').tolist()\n",
    "data_samples = df['fulltext'].tolist()\n",
    "\n",
    "\n",
    "#df=emoji_tag(df,writer)m\n",
    "\n",
    "# Post tagging if choice\n",
    "\n",
    "if is_tag==1:\n",
    "    print('Start tagging post')\n",
    "    list_var, df=kw_tag(df,lang)\n",
    "    stats_tags(df, list_var, enterprise_name, title,writer)\n",
    "\n",
    "# BASIC STAT\n",
    "#stats\n",
    "\n",
    "\n",
    "# LDA\n",
    "doc_topics, topics,frequence = do_lda(data_samples, lang, n_features, n_topics, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c9c05599e650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc_topics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtopic_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_topics' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_topics = pd.DataFrame(doc_topics)\n",
    "df['topic'] = doc_topics.idxmax(axis=1)\n",
    "topic_counts = df['topic'].value_counts()\n",
    "\n",
    "# OUTPUT\n",
    "\n",
    "#TODO : Rajouter pour chaque post la distribution des topics/le score par topic, plutôt que seulement un label du max de ces scores. Ca nous permettrait ensuite de calculer des distances inter-post.\n",
    "\n",
    "topics_tot=topics.join(topic_counts)\n",
    "topics_tot.to_excel(writer, sheet_name='desc_topic')\n",
    "\n",
    "\n",
    "\n",
    "# Export des posts avec gestion de l'écriture des urls dans excel\n",
    "\n",
    "list_var = [ \"topic\", 'fulltext', 'fulltext_original']\n",
    "\n",
    "df[list_var].drop_duplicates().to_excel(writer, sheet_name='post')\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=df[list_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_word=[topics_tot[0][int(i)] for i in dfs['topic'] ]\n",
    "len(top_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs['top_word'] = top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trouve=[re.search(dfs['top_word'][i]+\"*\",dfs['fulltext'][i], flags=0) for i in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trouve=[]\n",
    "for i in df.index:\n",
    "    if re.search(dfs['top_word'][i]+\"*\",dfs['fulltext'][i], flags=0)==None:\n",
    "        trouve.append(0)\n",
    "    else :\n",
    "        trouve.append(1)\n",
    "dfs['trouve'] = trouve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic=dfs.groupby(['topic', 'top_word'])['trouve'].sum()\n",
    "statistic=pd.DataFrame(statistic)\n",
    "topic_counts=dfs.groupby(['topic'])['topic'].count()\n",
    "topic_counts.values\n",
    "statistic['topic_counts']=topic_counts.values\n",
    "statistic['pourcentage']=statistic['trouve']/statistic['topic_counts']*100\n",
    "statistic=statistic.sort_values(by=['topic_counts','pourcentage'], ascending=False)\n",
    "statistic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
